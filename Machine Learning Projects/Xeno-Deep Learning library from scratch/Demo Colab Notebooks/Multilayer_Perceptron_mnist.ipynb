{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multilayer Perceptron-mnist.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2GT4lGX8_6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "a542a494-0993-41fd-86de-ca40aa9aa621"
      },
      "source": [
        "# Clone the entire repo.\n",
        "!git clone -l -s https://github.com/manncodes/xeno.git cloned-repo\n",
        "%cd cloned-repo\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'cloned-repo'...\n",
            "warning: --local is ignored\n",
            "remote: Enumerating objects: 169, done.\u001b[K\n",
            "remote: Counting objects:   0% (1/169)\u001b[K\rremote: Counting objects:   1% (2/169)\u001b[K\rremote: Counting objects:   2% (4/169)\u001b[K\rremote: Counting objects:   3% (6/169)\u001b[K\rremote: Counting objects:   4% (7/169)\u001b[K\rremote: Counting objects:   5% (9/169)\u001b[K\rremote: Counting objects:   6% (11/169)\u001b[K\rremote: Counting objects:   7% (12/169)\u001b[K\rremote: Counting objects:   8% (14/169)\u001b[K\rremote: Counting objects:   9% (16/169)\u001b[K\rremote: Counting objects:  10% (17/169)\u001b[K\rremote: Counting objects:  11% (19/169)\u001b[K\rremote: Counting objects:  12% (21/169)\u001b[K\rremote: Counting objects:  13% (22/169)\u001b[K\rremote: Counting objects:  14% (24/169)\u001b[K\rremote: Counting objects:  15% (26/169)\u001b[K\rremote: Counting objects:  16% (28/169)\u001b[K\rremote: Counting objects:  17% (29/169)\u001b[K\rremote: Counting objects:  18% (31/169)\u001b[K\rremote: Counting objects:  19% (33/169)\u001b[K\rremote: Counting objects:  20% (34/169)\u001b[K\rremote: Counting objects:  21% (36/169)\u001b[K\rremote: Counting objects:  22% (38/169)\u001b[K\rremote: Counting objects:  23% (39/169)\u001b[K\rremote: Counting objects:  24% (41/169)\u001b[K\rremote: Counting objects:  25% (43/169)\u001b[K\rremote: Counting objects:  26% (44/169)\u001b[K\rremote: Counting objects:  27% (46/169)\u001b[K\rremote: Counting objects:  28% (48/169)\u001b[K\rremote: Counting objects:  29% (50/169)\u001b[K\rremote: Counting objects:  30% (51/169)\u001b[K\rremote: Counting objects:  31% (53/169)\u001b[K\rremote: Counting objects:  32% (55/169)\u001b[K\rremote: Counting objects:  33% (56/169)\u001b[K\rremote: Counting objects:  34% (58/169)\u001b[K\rremote: Counting objects:  35% (60/169)\u001b[K\rremote: Counting objects:  36% (61/169)\u001b[K\rremote: Counting objects:  37% (63/169)\u001b[K\rremote: Counting objects:  38% (65/169)\u001b[K\rremote: Counting objects:  39% (66/169)\u001b[K\rremote: Counting objects:  40% (68/169)\u001b[K\rremote: Counting objects:  41% (70/169)\u001b[K\rremote: Counting objects:  42% (71/169)\u001b[K\rremote: Counting objects:  43% (73/169)\u001b[K\rremote: Counting objects:  44% (75/169)\u001b[K\rremote: Counting objects:  45% (77/169)\u001b[K\rremote: Counting objects:  46% (78/169)\u001b[K\rremote: Counting objects:  47% (80/169)\u001b[K\rremote: Counting objects:  48% (82/169)\u001b[K\rremote: Counting objects:  49% (83/169)\u001b[K\rremote: Counting objects:  50% (85/169)\u001b[K\rremote: Counting objects:  51% (87/169)\u001b[K\rremote: Counting objects:  52% (88/169)\u001b[K\rremote: Counting objects:  53% (90/169)\u001b[K\rremote: Counting objects:  54% (92/169)\u001b[K\rremote: Counting objects:  55% (93/169)\u001b[K\rremote: Counting objects:  56% (95/169)\u001b[K\rremote: Counting objects:  57% (97/169)\u001b[K\rremote: Counting objects:  58% (99/169)\u001b[K\rremote: Counting objects:  59% (100/169)\rremote: Counting objects:  60% (102/169)\u001b[K\rremote: Counting objects:  61% (104/169)\u001b[K\rremote: Counting objects:  62% (105/169)\u001b[K\rremote: Counting objects:  63% (107/169)\u001b[K\rremote: Counting objects:  64% (109/169)\u001b[K\rremote: Counting objects:  65% (110/169)\u001b[K\rremote: Counting objects:  66% (112/169)\u001b[K\rremote: Counting objects:  67% (114/169)\u001b[K\rremote: Counting objects:  68% (115/169)\u001b[K\rremote: Counting objects:  69% (117/169)\u001b[K\rremote: Counting objects:  70% (119/169)\u001b[K\rremote: Counting objects:  71% (120/169)\u001b[K\rremote: Counting objects:  72% (122/169)\u001b[K\rremote: Counting objects:  73% (124/169)\u001b[K\rremote: Counting objects:  74% (126/169)\u001b[K\rremote: Counting objects:  75% (127/169)\u001b[K\rremote: Counting objects:  76% (129/169)\u001b[K\rremote: Counting objects:  77% (131/169)\u001b[K\rremote: Counting objects:  78% (132/169)\u001b[K\rremote: Counting objects:  79% (134/169)\u001b[K\rremote: Counting objects:  80% (136/169)\u001b[K\rremote: Counting objects:  81% (137/169)\u001b[K\rremote: Counting objects:  82% (139/169)\u001b[K\rremote: Counting objects:  83% (141/169)\u001b[K\rremote: Counting objects:  84% (142/169)\u001b[K\rremote: Counting objects:  85% (144/169)\u001b[K\rremote: Counting objects:  86% (146/169)\u001b[K\rremote: Counting objects:  87% (148/169)\u001b[K\rremote: Counting objects:  88% (149/169)\u001b[K\rremote: Counting objects:  89% (151/169)\u001b[K\rremote: Counting objects:  90% (153/169)\u001b[K\rremote: Counting objects:  91% (154/169)\u001b[K\rremote: Counting objects:  92% (156/169)\u001b[K\rremote: Counting objects:  93% (158/169)\u001b[K\rremote: Counting objects:  94% (159/169)\u001b[K\rremote: Counting objects:  95% (161/169)\u001b[K\rremote: Counting objects:  96% (163/169)\u001b[K\rremote: Counting objects:  97% (164/169)\u001b[K\rremote: Counting objects:  98% (166/169)\u001b[K\rremote: Counting objects:  99% (168/169)\u001b[K\rremote: Counting objects: 100% (169/169)\u001b[K\rremote: Counting objects: 100% (169/169), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 169 (delta 77), reused 91 (delta 21), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (169/169), 11.29 MiB | 16.14 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "/content/cloned-repo\n",
            "'Demo Colab Notebooks'\t LICENSE      requirements.txt\t test.py\n",
            " examples\t\t README.rst   setup.py\t\t xeno\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8hTO3G49Bqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "\n",
        "import xeno\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    # data\n",
        "    print(\"loading data, please wait ...\")\n",
        "    mnist = fetch_openml('mnist_784', version=1, cache=True)\n",
        "    print('data loading is done ...')\n",
        "    X_train = mnist.data / 255.0\n",
        "    y_train = mnist.target\n",
        "    n_classes = np.unique(y_train).size\n",
        "\n",
        "    return n_classes, X_train, y_train\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJ864nJj9eK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "outputId": "c7a1f741-404b-4fec-aeb8-833e9dc34d20"
      },
      "source": [
        "def main(max_iter):\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=200, n_in=784, activation=xeno.activations.ReLU()))\n",
        "    model.add(xeno.layers.Dense(n_out=n_classes, activation=xeno.activations.Softmax()))\n",
        "    model.compile(loss=xeno.objectives.SCCE(), optimizer=xeno.optimizers.SGD())\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main2(max_iter):\n",
        "    # test Momentum optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=200, n_in=784, activation=xeno.activations.ReLU()))\n",
        "    model.add(xeno.layers.Dense(n_out=n_classes, activation=xeno.activations.Softmax()))\n",
        "    model.compile(loss=xeno.objectives.SCCE(), optimizer=xeno.optimizers.Momentum())\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main3(max_iter):\n",
        "    # test NesterovMomentum optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=200, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss=xeno.objectives.SCCE(), optimizer=xeno.optimizers.NesterovMomentum())\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main4(max_iter):\n",
        "    # test Adagrad optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=100, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss='scce', optimizer='adagrad')\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main5(max_iter):\n",
        "    # test RMSProp optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=100, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss='scce', optimizer='rmsprop')\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main6(max_iter):\n",
        "    # test Adadelta optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=100, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss='scce', optimizer='adadelta')\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main7(max_iter):\n",
        "    # test Adam optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=100, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss='scce', optimizer='adam')\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "def main8(max_iter):\n",
        "    # test Adamax optimizer\n",
        "\n",
        "    n_classes, X_train, y_train = get_data()\n",
        "\n",
        "    # model\n",
        "    print(\"building model ...\")\n",
        "    model = xeno.Model()\n",
        "    model.add(xeno.layers.Dense(n_out=100, n_in=784, activation='relu'))\n",
        "    model.add(xeno.layers.Softmax(n_out=n_classes))\n",
        "    model.compile(loss='scce', optimizer='adamax')\n",
        "\n",
        "    # train\n",
        "    print(\"train model ... \")\n",
        "    model.fit(X_train, xeno.utils.data.one_hot(y_train), max_iter=max_iter, validation_split=0.1)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main8(50)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loading data, please wait ...\n",
            "data loading is done ...\n",
            "building model ...\n",
            "train model ... \n",
            "iter 1, train-[loss 0.4294, acc 0.8864]; valid-[loss 0.2204, acc 0.9404]; \n",
            "iter 2, train-[loss 0.2342, acc 0.9343]; valid-[loss 0.1687, acc 0.9527]; \n",
            "iter 3, train-[loss 0.1870, acc 0.9473]; valid-[loss 0.1426, acc 0.9591]; \n",
            "iter 4, train-[loss 0.1586, acc 0.9556]; valid-[loss 0.1289, acc 0.9623]; \n",
            "iter 5, train-[loss 0.1388, acc 0.9608]; valid-[loss 0.1139, acc 0.9666]; \n",
            "iter 6, train-[loss 0.1239, acc 0.9651]; valid-[loss 0.1040, acc 0.9696]; \n",
            "iter 7, train-[loss 0.1122, acc 0.9688]; valid-[loss 0.0978, acc 0.9712]; \n",
            "iter 8, train-[loss 0.1025, acc 0.9717]; valid-[loss 0.0906, acc 0.9733]; \n",
            "iter 9, train-[loss 0.0942, acc 0.9736]; valid-[loss 0.0911, acc 0.9725]; \n",
            "iter 10, train-[loss 0.0874, acc 0.9762]; valid-[loss 0.0832, acc 0.9756]; \n",
            "iter 11, train-[loss 0.0812, acc 0.9776]; valid-[loss 0.0820, acc 0.9765]; \n",
            "iter 12, train-[loss 0.0760, acc 0.9791]; valid-[loss 0.0800, acc 0.9768]; \n",
            "iter 13, train-[loss 0.0709, acc 0.9803]; valid-[loss 0.0773, acc 0.9774]; \n",
            "iter 14, train-[loss 0.0669, acc 0.9821]; valid-[loss 0.0739, acc 0.9788]; \n",
            "iter 15, train-[loss 0.0630, acc 0.9827]; valid-[loss 0.0702, acc 0.9796]; \n",
            "iter 16, train-[loss 0.0598, acc 0.9840]; valid-[loss 0.0701, acc 0.9804]; \n",
            "iter 17, train-[loss 0.0565, acc 0.9847]; valid-[loss 0.0695, acc 0.9804]; \n",
            "iter 18, train-[loss 0.0535, acc 0.9854]; valid-[loss 0.0666, acc 0.9811]; \n",
            "iter 19, train-[loss 0.0510, acc 0.9865]; valid-[loss 0.0665, acc 0.9808]; \n",
            "iter 20, train-[loss 0.0483, acc 0.9876]; valid-[loss 0.0661, acc 0.9814]; \n",
            "iter 21, train-[loss 0.0460, acc 0.9882]; valid-[loss 0.0660, acc 0.9817]; \n",
            "iter 22, train-[loss 0.0438, acc 0.9886]; valid-[loss 0.0651, acc 0.9808]; \n",
            "iter 23, train-[loss 0.0414, acc 0.9896]; valid-[loss 0.0654, acc 0.9811]; \n",
            "iter 24, train-[loss 0.0396, acc 0.9900]; valid-[loss 0.0626, acc 0.9817]; \n",
            "iter 25, train-[loss 0.0380, acc 0.9906]; valid-[loss 0.0614, acc 0.9821]; \n",
            "iter 26, train-[loss 0.0360, acc 0.9913]; valid-[loss 0.0625, acc 0.9827]; \n",
            "iter 27, train-[loss 0.0346, acc 0.9919]; valid-[loss 0.0611, acc 0.9825]; \n",
            "iter 28, train-[loss 0.0332, acc 0.9923]; valid-[loss 0.0597, acc 0.9832]; \n",
            "iter 29, train-[loss 0.0316, acc 0.9925]; valid-[loss 0.0617, acc 0.9822]; \n",
            "iter 30, train-[loss 0.0302, acc 0.9929]; valid-[loss 0.0594, acc 0.9827]; \n",
            "iter 31, train-[loss 0.0291, acc 0.9935]; valid-[loss 0.0604, acc 0.9828]; \n",
            "iter 32, train-[loss 0.0277, acc 0.9939]; valid-[loss 0.0597, acc 0.9822]; \n",
            "iter 33, train-[loss 0.0267, acc 0.9941]; valid-[loss 0.0607, acc 0.9827]; \n",
            "iter 34, train-[loss 0.0253, acc 0.9946]; valid-[loss 0.0586, acc 0.9834]; \n",
            "iter 35, train-[loss 0.0244, acc 0.9951]; valid-[loss 0.0599, acc 0.9824]; \n",
            "iter 36, train-[loss 0.0234, acc 0.9951]; valid-[loss 0.0614, acc 0.9818]; \n",
            "iter 37, train-[loss 0.0225, acc 0.9953]; valid-[loss 0.0592, acc 0.9821]; \n",
            "iter 38, train-[loss 0.0214, acc 0.9958]; valid-[loss 0.0602, acc 0.9821]; \n",
            "iter 39, train-[loss 0.0207, acc 0.9964]; valid-[loss 0.0593, acc 0.9827]; \n",
            "iter 40, train-[loss 0.0197, acc 0.9964]; valid-[loss 0.0590, acc 0.9835]; \n",
            "iter 41, train-[loss 0.0190, acc 0.9968]; valid-[loss 0.0593, acc 0.9825]; \n",
            "iter 42, train-[loss 0.0181, acc 0.9971]; valid-[loss 0.0594, acc 0.9829]; \n",
            "iter 43, train-[loss 0.0174, acc 0.9973]; valid-[loss 0.0592, acc 0.9835]; \n",
            "iter 44, train-[loss 0.0167, acc 0.9972]; valid-[loss 0.0601, acc 0.9824]; \n",
            "iter 45, train-[loss 0.0161, acc 0.9975]; valid-[loss 0.0590, acc 0.9831]; \n",
            "iter 46, train-[loss 0.0154, acc 0.9977]; valid-[loss 0.0612, acc 0.9822]; \n",
            "iter 47, train-[loss 0.0148, acc 0.9980]; valid-[loss 0.0598, acc 0.9831]; \n",
            "iter 48, train-[loss 0.0142, acc 0.9979]; valid-[loss 0.0600, acc 0.9827]; \n",
            "iter 49, train-[loss 0.0135, acc 0.9980]; valid-[loss 0.0618, acc 0.9827]; \n",
            "iter 50, train-[loss 0.0131, acc 0.9983]; valid-[loss 0.0624, acc 0.9827]; \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}