{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-pO2oZXe2pv",
        "outputId": "37069dea-c35c-4492-d153-b8f617abb6e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "try:\n",
        "  fastbook.setup_book()\n",
        "except:\n",
        "  print(\"No password entered\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 727kB 4.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 21.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 194kB 46.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 40kB 5.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 11.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 61kB 8.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.6MB 39.5MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "No password entered\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppki7EByfWIz"
      },
      "source": [
        "from fastbook import *\n",
        "from IPython.display import display, HTML"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I88mGp6k43ms"
      },
      "source": [
        "## NLP introduction\n",
        "\n",
        "nlp is about guessing the next word. for that the model needs to create its own labels. It uses self supervised learning.\n",
        "\n",
        "The language model used to classify IMDb was pretrained on Wikipedia. \n",
        "\n",
        "why learn in detail ?\n",
        "\n",
        "One reason, of course, is that it is helpful to understand the foundations of the models that you are using. But there is another very practical reason, which is that you get even better results if you fine-tune the (sequence-based) language model prior to fine-tuning the classification model\n",
        "\n",
        "We will be finetuning the pretrained language model which was trained on wikipedia articles.\n",
        "\n",
        "This is called ULMFit approach.\n",
        "\n",
        "### text preprocessing\n",
        "\n",
        "we already know how categorical variables can be used as independent variables for neural network\n",
        "\n",
        "make a list of all possible levels of the variable (vocab)\n",
        "\n",
        "Replace each level with its index in the vocab\n",
        "\n",
        "create an embedding matrix for this contatining a row for each level i.e. for each item in the vocab\n",
        "\n",
        "Use this embedding matrix as the first layer of a neural network.\n",
        "\n",
        "we do the same thing with text. \n",
        "\n",
        "whats new is idea of sequence. first we concatenate all of the document in our dataset into onw big long string and split it into words giving us very long words or tokens. \n",
        "\n",
        "Our independent variable will be the entire string exect for the second last and last will be labe;\n",
        "\n",
        "Our vocab would be mix of common words from wikipedia and new words specific to our corpus would be movie actors\n",
        "\n",
        "for building embedding matrix: for words in vocabualary of pre trained modelwe will take corresponding row in the embedding matrix of the pretrained model but for new words we won't have anythong, we willjust initialize the corresponding row with a random vector\n",
        "\n",
        "jargon\n",
        "\n",
        "tokenisation\n",
        "\n",
        "Numericalisations - making list of unique words -vocab and convert each word to index to look up in vocab\n",
        "\n",
        "Language model data loader creation -  LMDDataLoader class for seperating the last token as label\n",
        "\n",
        "Language model creation - creating a model that handles the input list that are arbitaryily small or big."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw0ysUpNMhQz"
      },
      "source": [
        "### Tokenisation\n",
        "\n",
        "converting to words\n",
        " word based - split a sentence on spaces and apply language specific rules to try to seperate parts of meaning even when there are no spaces\n",
        "\n",
        " subword - word is split like occ aa sion\n",
        "\n",
        " Character based - individual character\n",
        "\n",
        " with fastai word tokenisation is done through exernal API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zltl7zWxfssL",
        "outputId": "7a6e634d-2bf8-4554-d775-b8fa62a560c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "from fastai.text.all import *\n",
        "path = untar_data(URLs.IMDB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VsT8CSRKNfAC"
      },
      "source": [
        "need to gradb the text file, like get_imagefiles we have get_text_file.\n",
        "\n",
        "we can also pass folder to restrict the search"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72cCnGYjxCZR",
        "outputId": "1227c15a-c283-437f-b523-520c769215c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!dir {path}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "imdb.vocab  README  test  tmp_clas  tmp_lm  train  unsup\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiLVdGxANWcn"
      },
      "source": [
        "files = get_text_files(path, folders=['train', 'test', 'unsup'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vupmfimgNzBj",
        "outputId": "97db8db7-0591-4259-d26e-67db4844a7fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "txt = files[0].open().read()\n",
        "txt[:75]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'There are a number of things that are not correct, although this is not too'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCeII5zIOAkz"
      },
      "source": [
        "fastai by default used spacyTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgg1fu18N6-1",
        "outputId": "cbe6b33b-e034-4e92-a286-6144d8f38063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "spacy = WordTokenizer()\n",
        "toks = first(spacy([txt]))\n",
        "print(toks)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['There', 'are', 'a', 'number', 'of', 'things', 'that', 'are', 'not', 'correct', ',', 'although', 'this', 'is', 'not', 'too', 'important', 'since', 'what', 'happened', 'to', 'whom', 'and', 'when', 'is', 'still', 'in', 'dispute', '.', 'The', 'most', 'blatant', 'liberty', 'with', 'the', 'facts', 'I', 'think', 'is', 'when', 'they', 'start', 'to', 'play', 'at', 'Bruno', 'Koschmidder', \"'s\", 'Kaiserkeller', ',', 'when', 'in', 'fact', 'they', 'played', 'at', 'the', 'Indra', 'and', 'moved', 'to', 'the', 'Kaiserkeller', 'later.<br', '/><br', '/>I', 'agree', 'with', 'Semprinni20', 'that', 'the', 'film', 'was', 'biased', 'in', 'favour', 'of', 'Pete', 'Best', \"'s\", 'version', ',', 'but', 'if', 'he', 'is', 'the', 'story', 'consultant', 'then', 'I', 'guess', 'he', 'calls', 'the', 'shots', '.', 'I', 'also', 'agree', 'with', 'Semprinni', 'that', 'the', 'recordings', 'Pete', 'Best', 'plays', 'on', 'say', 'the', 'last', 'word', 'on', 'the', 'subject', 'of', 'why', 'he', 'was', 'fired.<br', '/><br', '/>Although', 'the', 'film', 'is', 'not', 'such', 'a', 'lavish', 'production', 'as', 'the', 'later', 'film', '\"', 'Backbeat', '\"', ',', 'I', 'prefer', 'this', 'film', 'because', 'it', 'is', 'more', 'accurate', ',', 'and', 'because', 'it', 'has', 'a', 'better', 'script', 'with', 'deeper', 'characterisation.<br', '/><br', '/>There', 'is', 'plenty', 'in', 'the', 'film', 'that', 'is', 'quite', 'substantial', '-', 'such', 'as', 'Brian', 'Epstein', 'trying', 'to', 'hide', 'the', 'fact', 'that', 'he', 'has', 'been', '\"', 'queer', '-', 'bashed', ',', '\"', 'only', 'to', 'find', 'out', 'that', 'the', 'band', 'knew', 'he', 'was', 'Gay', 'all', 'along', '.', 'Little', 'touches', 'like', 'the', 'band', 'going', 'into', 'a', 'café', 'and', 'ordering', '\"', 'Corn', '-', 'Flakes', 'mit', 'Milch', '.', '\"', 'My', 'favourite', 'scene', ',', 'which', 'does', 'have', 'some', 'bassis', 'in', 'fact', ',', 'is', 'where', 'at', 'an', 'audition', 'Stuart', 'Sutcliffe', 'has', 'just', 'bought', 'his', 'bass', 'guitar', 'but', 'ca', \"n't\", 'play', 'it', ',', 'so', 'he', 'stands', 'with', 'his', 'back', 'to', 'the', 'impresario', 'and', 'tries', 'faking', 'it', ',', 'but', 'gets', 'caught', '.', 'That', \"'s\", 'rock', \"'\", 'n', \"'\", 'roll.<br', '/><br', '/>Well', 'worth', 'watching', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTeeYsSwOmHW",
        "outputId": "4c9fee01-fa87-46e3-9e79-d09a38f9ea0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "first(spacy(['The U.S. dollar $1 is $1.00']))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#8) ['The','U.S.','dollar','$','1','is','$','1.00']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vOypO_s_QiJr",
        "outputId": "42854026-4666-4046-d744-d1673380ffe4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# some additional functionality is added to Tokenizer class\n",
        "\n",
        "tkn = Tokenizer(spacy)\n",
        "\n",
        "print(tkn(txt))\n",
        "\n",
        "# xxbos indicates beginning of the stream"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['xxbos', 'xxmaj', 'there', 'are', 'a', 'number', 'of', 'things', 'that', 'are', 'not', 'correct', ',', 'although', 'this', 'is', 'not', 'too', 'important', 'since', 'what', 'happened', 'to', 'whom', 'and', 'when', 'is', 'still', 'in', 'dispute', '.', 'xxmaj', 'the', 'most', 'blatant', 'liberty', 'with', 'the', 'facts', 'i', 'think', 'is', 'when', 'they', 'start', 'to', 'play', 'at', 'xxmaj', 'bruno', 'xxmaj', 'koschmidder', \"'s\", 'xxmaj', 'kaiserkeller', ',', 'when', 'in', 'fact', 'they', 'played', 'at', 'the', 'xxmaj', 'indra', 'and', 'moved', 'to', 'the', 'xxmaj', 'kaiserkeller', 'later', '.', '\\n\\n', 'i', 'agree', 'with', 'xxmaj', 'semprinni20', 'that', 'the', 'film', 'was', 'biased', 'in', 'favour', 'of', 'xxmaj', 'pete', 'xxmaj', 'best', \"'s\", 'version', ',', 'but', 'if', 'he', 'is', 'the', 'story', 'consultant', 'then', 'i', 'guess', 'he', 'calls', 'the', 'shots', '.', 'i', 'also', 'agree', 'with', 'xxmaj', 'semprinni', 'that', 'the', 'recordings', 'xxmaj', 'pete', 'xxmaj', 'best', 'plays', 'on', 'say', 'the', 'last', 'word', 'on', 'the', 'subject', 'of', 'why', 'he', 'was', 'fired', '.', '\\n\\n', 'xxmaj', 'although', 'the', 'film', 'is', 'not', 'such', 'a', 'lavish', 'production', 'as', 'the', 'later', 'film', '\"', 'backbeat', '\"', ',', 'i', 'prefer', 'this', 'film', 'because', 'it', 'is', 'more', 'accurate', ',', 'and', 'because', 'it', 'has', 'a', 'better', 'script', 'with', 'deeper', 'characterisation', '.', '\\n\\n', 'xxmaj', 'there', 'is', 'plenty', 'in', 'the', 'film', 'that', 'is', 'quite', 'substantial', '-', 'such', 'as', 'xxmaj', 'brian', 'xxmaj', 'epstein', 'trying', 'to', 'hide', 'the', 'fact', 'that', 'he', 'has', 'been', '\"', 'queer', '-', 'bashed', ',', '\"', 'only', 'to', 'find', 'out', 'that', 'the', 'band', 'knew', 'he', 'was', 'xxmaj', 'gay', 'all', 'along', '.', 'xxmaj', 'little', 'touches', 'like', 'the', 'band', 'going', 'into', 'a', 'café', 'and', 'ordering', '\"', 'corn', '-', 'flakes', 'mit', 'xxmaj', 'milch', '.', '\"', 'xxmaj', 'my', 'favourite', 'scene', ',', 'which', 'does', 'have', 'some', 'bassis', 'in', 'fact', ',', 'is', 'where', 'at', 'an', 'audition', 'xxmaj', 'stuart', 'xxmaj', 'sutcliffe', 'has', 'just', 'bought', 'his', 'bass', 'guitar', 'but', 'ca', \"n't\", 'play', 'it', ',', 'so', 'he', 'stands', 'with', 'his', 'back', 'to', 'the', 'impresario', 'and', 'tries', 'faking', 'it', ',', 'but', 'gets', 'caught', '.', 'xxmaj', 'that', \"'s\", 'rock', \"'\", 'n', \"'\", 'roll', '.', '\\n\\n', 'xxmaj', 'well', 'worth', 'watching', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mflWbqdoRPr6",
        "outputId": "39a268a3-2be1-4d81-ebac-d5d8603f878f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        "defaults.text_proc_rules"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<function fastai.text.core.fix_html>,\n",
              " <function fastai.text.core.replace_rep>,\n",
              " <function fastai.text.core.replace_wrep>,\n",
              " <function fastai.text.core.spec_add_spaces>,\n",
              " <function fastai.text.core.rm_useless_spaces>,\n",
              " <function fastai.text.core.replace_all_caps>,\n",
              " <function fastai.text.core.replace_maj>,\n",
              " <function fastai.text.core.lowercase>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvRpCRzHRX5o"
      },
      "source": [
        "#??replace_rep"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAU31o6sRi5i",
        "outputId": "d0213ae0-ba70-443e-9749-90e5beb88061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "coll_repr(tkn('&copy; Fast.ai ww.fast.ai/INDEX'), 31)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#8) ['xxbos','©','xxmaj','fast.ai','ww.fast.ai','/','xxup','index']\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu4s3qENRx_y"
      },
      "source": [
        "### subword tokenisation\n",
        "\n",
        "Used especially in language like chinese as they have no spaces\n",
        "\n",
        "then we \n",
        "1. analyse the corpus for most commonly occuring grouping\n",
        "2. tokenize using the vocab of subword units"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnqz1BETRsof"
      },
      "source": [
        "txts = L(o.open().read() for o in files[:2000])\n",
        "# L behaves like a list of items with extra functionalities"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ut69WKSUiiN",
        "outputId": "83a3baa7-6bbf-4c5f-ab0b-8a912ca557dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "txts"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#2000) ['There are a number of things that are not correct, although this is not too important since what happened to whom and when is still in dispute. The most blatant liberty with the facts I think is when they start to play at Bruno Koschmidder\\'s Kaiserkeller, when in fact they played at the Indra and moved to the Kaiserkeller later.<br /><br />I agree with Semprinni20 that the film was biased in favour of Pete Best\\'s version, but if he is the story consultant then I guess he calls the shots. I also agree with Semprinni that the recordings Pete Best plays on say the last word on the subject of why he was fired.<br /><br />Although the film is not such a lavish production as the later film \"Backbeat\", I prefer this film because it is more accurate, and because it has a better script with deeper characterisation.<br /><br />There is plenty in the film that is quite substantial - such as Brian Epstein trying to hide the fact that he has been \"queer-bashed,\" only to find out that the band knew he was Gay all along. Little touches like the band going into a café and ordering \"Corn-Flakes mit Milch.\" My favourite scene, which does have some bassis in fact, is where at an audition Stuart Sutcliffe has just bought his bass guitar but can\\'t play it, so he stands with his back to the impresario and tries faking it, but gets caught. That\\'s rock \\'n\\' roll.<br /><br />Well worth watching.','This movie is one of those \"WOW!\" movies. Not because it\\'s the greatest movie of all time, but because it surprised me. Not only was it a T.V. movie, but it was on Elvis. I can safely say as many impersonators as there are there was only one Elvis, but I can also safely say that Kurt Russel came extremely close to being the real thing. It was one of the greatest impersonations that I have ever seen. He had me believing that it was really him. I learned a lot about Elvis\\' life from watching this movie. And don\\'t led the television part of it let you stray-it\\'s actually a really fantastic film! And Kurt Russel could\\'ve been Elvis\\' twin :)','I was looking through the movie listings in my area on yahoo and seen a movie that had not been advertised. I looked closer and noticed that Peter Falk and Paul Reiser were in it. Having watched \"Mad about you\", once, I was not a fan of Paul Reiser. However, I am a big fan of Peter Falk. So the spouse and I took a chance. We were both swept into this story. The beautiful scenery, the heartfelt acting and the sense of family and moral values that are seldom seen in movies and the world today. Not that sappy emoted junk, but real life situations from real life-like people. I even have to say, Paul Reiser was excellent, although, I still won\\'t watch \"Mad about you\". I don\\'t know where this movie has gone. I heard it was put out in limited release. It should be shared with the world. It is one of the finest movies I have seen. M.',\"ROAD TO PERDITION can be summed up by Thomas Newman's score . It's haunting and beautiful but you're aware that this music is similar to Newman's other work and while listening to the soundtrack you're reminded of SCENT OF A WOMAN , MEETING JOE BLACK and THE SHAWSHANK REDEMPTION you're reminded of other films as the story unfolds on screen . As the Sullivans drive round America trying to escape from a psychotic hit man you think of THE GETAWAY , Irish gangsters is MILLER'S CROSSING whilst the subtext of guilt and redemption can be summed up by Coppola and Leone's gangster epics. Despite having a seen it all before feel this shouldn't be taken as a heavy criticism of Sam Mendes film which I repeat is haunting and beautiful and the only flaws that work against it is a very slow opening twenty minutes and I was slightly confused as the events that caused Michael Sullivan to be betrayed . But if you stop to consider how much of a sentimental mess Spielberg might have made with the story that revolves around a father and his twelve year old son running for their lives you can't help thinking what a superb director Mendes is <br /><br />ROAD TO PERDITION is a film where the entire cast give flawless performances . I've never been all that keen on Tom Hanks but he's every bit as good here as he has been in any starring role , probably better . Paul Newman plays a character with an Irish accent but at no point did I believe I was watching an American screen legend putting on a false accent - Newman's performance works due to the subtle body language , his character is torn up by guilt but Newman never milks it or goes over the top . While never upstaging Newman who gives the best performance in the movie the two Brit supporting actors Craig and Law are also very memorable as American gangsters and while Law will still have a long career as a leading actor one wonders how Daniel Craig might have progressed as a character actor if he hadn't decided to become James Bond , a role which heralds the end of an actors career\",'The movie has a great written genre story. It features all of the usual Columbo ingredients; The way Lt. Columbo approaches and bonds to his suspect, the way the mystery unravels for him, Columbo\\'s dog, the cat and mouse play, which is great in this one and luckily as well some good relieving humor, mostly involving the Columbo character. It\\'s all written despite the fact that it doesn\\'t even have a truly original concept. Columbo hunting down a detective/murder novel writer had been done more than once before in a Columbo movie.<br /><br />It\\'s also an extremely well directed movie from James Frawley, who after this directed 5 more Columbo movies, in the \\'70\\'s and \\'80\\'s. He provided the movie with style and some truly great and memorable sequences.<br /><br />It\\'s one of the slower moving Columbo movies, despite not having a too long running time. This style and approach doesn\\'t always work out well for a Columbo movie but in this movie it does, which is perhaps not in the least thanks to the acting performances of the movie.<br /><br />Most Columbo movie either starred a big well known star or a star from the early days of film-making, as the movie its murderer. This movie stars the rather unknown 81 year old Ruth Gordon. She didn\\'t starred in an awful lot of movies throughout her career but she is still well known to some, mostly for her role in \"Rosemary\\'s Baby\", which also won her an Oscar. She had a realistic and somewhat unusual style of acting, which some people might not like though. It earned her 4 more Oscar nominations throughout her career, prior to her win for \"Rosemary\\'s Baby\", in 1969. She has some great interaction as well with Peter Falk in their sequences together.<br /><br />The movie also stars a still young G.D. Spradlin. I say young because I only know him from his latest productions out of his career, despite the fact that he already was 57 at the time of this Columbo production. He is still alive but retired from acting, ever since 1999.<br /><br />An even better than usual Columbo movie entry.<br /><br />8/10',\"Clara Lago is wonderful as the title character of the film, essentially a film about a Spanish/American girl who moves to Spain with her mom at the time of the Spanish Civil War. It turns out, the mother goes home to die, and she is left with her grandfather. She also makes friends and experiences much in a short time. Tomiche (Juan Jose Ballestra) is at first a nuisance to her then they become close. The film is shot beautifully, bathed in soft colors mostly. Carol yearns for her dad, who is a pilot in the war, and you can feel the love sher has for him. While the war itself is kind of taken a back seat in this film, it envelops the character's lives. I think you'll like it. See it especially for Clara Lago, who does a great job as Carol. She is definitely one to watch.\",\"The arrival of White Men in Arctic Canada challenges the freedom of a fearless ESKIMO hunter.<br /><br />W. S. Van Dyke, MGM's peripatetic director, was responsible for this fascinating look at life in the Arctic among the Inuit. His production was on location filming from April 1932 until November 1933 (although some annoying rear projection effects show that some of the shooting took place back at the Studio). While considered a documentary at the time, we would likely term it a 'docudrama' as it is scripted with an intriguing plot & storyline.<br /><br />The film shows the daily life of the Eskimo, both Winter & Summer, and in fact starts in the warmer time of the year without any snow or ice in sight. The constant striving for food is depicted, and the viewer gets to watch the exciting hunts for walrus, polar bear, whale & caribou. The native language is used throughout, with the use of title cards; the only English is spoken by the fishermen & Mounties encountered by the Eskimo. In fact, it is the arrival of White Men, both good & bad, and the change they make on Eskimo society, which is a major element in the narrative.<br /><br />This Pre-Code film deals in a refreshingly frank manner with the Eskimo moral code, particularly with their practice of wife-sharing, which was an important and completely innocent part of their culture. In fact, the entire film can be appreciated as a valuable look at a way of life which was rapidly disappearing even in the early 1930's.<br /><br />None of the cast receives screen credit, which is a shame as there are some notable performances. Foremost among them is that of Ray Wise, playing the leading role of Mala the Eskimo. Wise (1906-1952) was an Alaskan Native of Inuit ancestry and is absolutely splendid and perfectly believable in what was a very demanding part. As handsome as any Hollywood star, he would continue acting, using the name of Ray Mala, in a sporadic film career, often in tiny unbilled roles.<br /><br />Lovely Japanese-Hawaiian actress Lotus Long plays Mala's loyal second wife; the names of the fine actresses playing his other two wives are now obscure. Director Woody Van Dyke steps in front of the cameras as a strict North West Mounted Police inspector. The two decent-hearted Mounties who must deliver Mala to Canadian justice are played by Joe Sawyer & Edgar Dearing, both longtime movie character actors. Danish author Peter Freuchen, upon whose books the film was based, has a short vivid role of an evil wooden-legged sea captain who unwisely rouses Mala's icy wrath.\",\"This film isn't just about a school shooting, in fact its never even seen. But that just adds to the power this film has. Its about people and how they deal with tragedy. I know it was shown to the students who survived the Columbine shooting and it provided a sense of closure for a lot of them. The acting is superb. All three main actors (Busy Phillips, Erika Christensen and Victor Garber) are excellent in their roles...I highly recommend this film to anyone. Its one of those films that makes you talk about it after you see it. It provokes discussion of not only school shootings but of human emotions and reactions to all forms of tragedy. It is a tear-jerker but it is well worth it and one i will watch time and time again\",'Richard Dreyfuss stars in \"Moon Over Parador,\" a 1988 Paul Mazursky film also starring Raul Julia, Sonia Braga, Jonathan Winters and Charo. Dreyfuss plays a New York actor, Jonathan Nolan, in the Caribbean country of Parador to make a film. When the dictator dies suddenly, the Secret Police Chief (Julia) who is the one actually controlling the dictator and the country, drafts Jonathan to play the dictator, having noticed the resemblance between them. Soon Jonathan is ensconced in the palace as Alphonse Simms, and Simms\\' prostitute girlfriend Madonna (Braga) who realizes the switch promises to help him in any way she can.<br /><br />Mazursky, who appears in drag as Simms\\' mother, gives us a look at how the CIA operates in third world countries. The Winters character, supposedly a salesman, is actually a CIA operative. The film, however, flirts with but doesn\\'t really tread on very serious ground and is more of a send-up, and a funny one at that.<br /><br />Richard Dreyfuss does a fabulous job as Jonathan the actor and Alphonse the dictator, creating two separate characters and nailing both. The gorgeous Sonia Braga is great as Madonna, and Raul Julia hands in a wickedly funny performance as Strausmann, the man behind the dictator. It\\'s one of those performances where you never quite know what the character is thinking - he can be pleasant or turn psycho at any moment. Charo is on hand as a maid and manages to be funny and unobtrusive at the same time.<br /><br />A very good film, not a big blockbuster, but very entertaining.',\"I find Alan Jacobs review very accurate concerning the movie;however I had the opportunity to rent the DVD from blockbuster with a commentary from BYU's Curator, Motion Picture Archives James D'Arc. The then LDS Prophet Heber J. Grant approved of the movie understanding the deviations from historic content for dramatic expression and telescoping events. For example the movie showed Joseph Smith on trial. despite Brigham Young's great oratory in defense of Joseph Smith he was convicted anyway. Then Joseph was killed. Historically Joseph Smith was never convicted of anything. Brigham Young was in Boston when Joseph Smith was arrested for this particular trial. Joseph Smith and his brother Hyrum where both killed before the trial took place.\"...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xPF5ZHgSa4b"
      },
      "source": [
        "we instantiate the tokeniser passing in the size of vocab and then find the common sequences of characters to create the vocab. this is done with setup. it is called automatically but we are doing ti here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQI1pTujSNCO"
      },
      "source": [
        "def subword(sz):\n",
        "    sp = SubwordTokenizer(vocab_sz=sz)\n",
        "    sp.setup(txts)\n",
        "    return ' '.join(first(sp([txts]))[:40])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_imJA-7XVG2H",
        "outputId": "c3c590b9-98a5-4197-b2cc-d9dbb2cb042d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sp = SubwordTokenizer(vocab_sz=1000)\n",
        "sp.setup(txts)\n",
        "print(sp([txts]))\n",
        "for i in str(sp([txts])):\n",
        "  print(str(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "<generator object SentencePieceTokenizer.__call__ at 0x7f4171b0ca98>\n",
            "<\n",
            "g\n",
            "e\n",
            "n\n",
            "e\n",
            "r\n",
            "a\n",
            "t\n",
            "o\n",
            "r\n",
            " \n",
            "o\n",
            "b\n",
            "j\n",
            "e\n",
            "c\n",
            "t\n",
            " \n",
            "S\n",
            "e\n",
            "n\n",
            "t\n",
            "e\n",
            "n\n",
            "c\n",
            "e\n",
            "P\n",
            "i\n",
            "e\n",
            "c\n",
            "e\n",
            "T\n",
            "o\n",
            "k\n",
            "e\n",
            "n\n",
            "i\n",
            "z\n",
            "e\n",
            "r\n",
            ".\n",
            "_\n",
            "_\n",
            "c\n",
            "a\n",
            "l\n",
            "l\n",
            "_\n",
            "_\n",
            " \n",
            "a\n",
            "t\n",
            " \n",
            "0\n",
            "x\n",
            "7\n",
            "f\n",
            "4\n",
            "1\n",
            "7\n",
            "1\n",
            "b\n",
            "0\n",
            "c\n",
            "a\n",
            "9\n",
            "8\n",
            ">\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5yI_bMlT-mV"
      },
      "source": [
        "#subword(1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_l-dx_7b7d5W"
      },
      "source": [
        "If er use samller vocab then each token would be smaller bbut it will take more tokens to represent a sentence.\n",
        "\n",
        "I its large then most common phrases themselves would be in vocab\n",
        "\n",
        "subwords are important because then we can also train on genomic sequence and MIDI music data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dft49j2c8NSN"
      },
      "source": [
        "### Numericalisation\n",
        "\n",
        "IN this we map the token to integers. It is similar to steps needded to create a categorical model.\n",
        "\n",
        "in this we make a list of all possible levels of that categorical variable\n",
        "\n",
        "Replace each level with index in vocab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxWlVAOBUbWQ",
        "outputId": "94ee3ca4-63b0-4e95-fbda-df213637a7bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "toks = tkn(txt)\n",
        "\n",
        "print(coll_repr(tkn(txt), 5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(#314) ['xxbos','xxmaj','there','are','a'...]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uImBVVj492-C"
      },
      "source": [
        "in orderto use numericalise we need to call setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rrgqSAyLw_WR",
        "outputId": "7ec5ca60-d816-4bb6-f4ae-1782ab5219d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "toks200 = txts[:200].map(tkn)\n",
        "toks200[199]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#131) ['xxbos','\"','after','dark',',','my','sweet','\"','is','a'...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4odh7kF-xwg",
        "outputId": "daa6b6c6-68e5-450e-aa8b-8dc504bb3c9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "num = Numericalize()\n",
        "num.setup(toks200)\n",
        "coll_repr(num.vocab, 20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"(#2184) ['xxunk','xxpad','xxbos','xxeos','xxfld','xxrep','xxwrep','xxup','xxmaj','the',',','.','and','a','of','to','is','in','it','that'...]\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oREiYhsCoY3"
      },
      "source": [
        "thedefaults to Numericalize are min_freq=2 and max _vocab=60000 this results in fastai replacing all words other than the most common 60 000 with a special unknown word token xxunk.\n",
        "\n",
        "this is to avoid overly large embedding matrix\n",
        "\n",
        "after creating num we can use it like a token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1iiC8PwgBwYo",
        "outputId": "ce690cf3-cb7b-4dd0-c57b-eab3e7cc64fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "nums = num(toks)[:20]\n",
        "nums"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   8,  67,  41,  13, 440,  14, 207,  19,  41,  42,   0,  10, 281,  20,  16,  42, 130, 515, 247])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAZuoPzaDynd"
      },
      "source": [
        "they can be mapped back intooriginal text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1PrIqPlDlCg",
        "outputId": "2a7beda4-e385-4070-c4a2-fd995f9ac454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "num.vocab[20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'this'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfZUlI1ND9CR"
      },
      "source": [
        "### Putting text into batches for a language Model\n",
        "\n",
        "two considerations : irregular length and importance of begining when the previous batch left off"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqzxxrMMD7Gp",
        "outputId": "07673830-d475-4f57-e5ea-cb11a9beae2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "stream = \"In this chapter, we will go over what has been done previously and try to be the best thing that ever got into the the history of these leaves. To be frank I never expected me to be the kind of guy who would follow through. But what do you kno here we are doing what we do worst. You can't be at your best everytime, however the problem is I am at my worst more time htan I would like. And to make matters worse I rarely learn.\"\n",
        "tokens = tkn(stream)\n",
        "bs, seq_len = 6, 15\n",
        "d_tokens = np.array( [ tokens[i*seq_len:(i+1)*seq_len] for i in range(bs)])\n",
        "df = pd.DataFrame(d_tokens)\n",
        "display(HTML(df.to_html(index=False, header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>over</td>\n",
              "      <td>what</td>\n",
              "      <td>has</td>\n",
              "      <td>been</td>\n",
              "      <td>done</td>\n",
              "      <td>previously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "      <td>into</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>history</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "      <td>me</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>kind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "      <td>do</td>\n",
              "      <td>you</td>\n",
              "      <td>kno</td>\n",
              "      <td>here</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "      <td>n't</td>\n",
              "      <td>be</td>\n",
              "      <td>at</td>\n",
              "      <td>your</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "      <td>worst</td>\n",
              "      <td>more</td>\n",
              "      <td>time</td>\n",
              "      <td>htan</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAuPYw5eJOoh"
      },
      "source": [
        "we cant simple give the above words to model because of GPU restrictions.\n",
        "\n",
        "Sowe neeedto devide this array more finely into subarrays of fixed sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qt-SJtAaJGmN",
        "outputId": "661a774a-0645-4a39-e6d9-a9a5ee293a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# if we want a sequence len of five for 6 batches of length 15\n",
        "\n",
        "bs, seq_len = 6, 5\n",
        "for j in range(0,15):\n",
        "  d_tokens = np.array([tokens[i*15:i*15+j * seq_len] for i in range(bs)])\n",
        "  df = pd.DataFrame(d_tokens)\n",
        "  display(HTML(df.to_html(index=False, header=None)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "    </tr>\n",
              "    <tr>\n",
              "    </tr>\n",
              "    <tr>\n",
              "    </tr>\n",
              "    <tr>\n",
              "    </tr>\n",
              "    <tr>\n",
              "    </tr>\n",
              "    <tr>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>over</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>over</td>\n",
              "      <td>what</td>\n",
              "      <td>has</td>\n",
              "      <td>been</td>\n",
              "      <td>done</td>\n",
              "      <td>previously</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "      <td>into</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>history</td>\n",
              "      <td>of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "      <td>me</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>kind</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "      <td>do</td>\n",
              "      <td>you</td>\n",
              "      <td>kno</td>\n",
              "      <td>here</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "      <td>n't</td>\n",
              "      <td>be</td>\n",
              "      <td>at</td>\n",
              "      <td>your</td>\n",
              "      <td>best</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "      <td>worst</td>\n",
              "      <td>more</td>\n",
              "      <td>time</td>\n",
              "      <td>htan</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>over</td>\n",
              "      <td>what</td>\n",
              "      <td>has</td>\n",
              "      <td>been</td>\n",
              "      <td>done</td>\n",
              "      <td>previously</td>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "      <td>into</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>history</td>\n",
              "      <td>of</td>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "      <td>me</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>kind</td>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "      <td>do</td>\n",
              "      <td>you</td>\n",
              "      <td>kno</td>\n",
              "      <td>here</td>\n",
              "      <td>we</td>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "      <td>n't</td>\n",
              "      <td>be</td>\n",
              "      <td>at</td>\n",
              "      <td>your</td>\n",
              "      <td>best</td>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "      <td>worst</td>\n",
              "      <td>more</td>\n",
              "      <td>time</td>\n",
              "      <td>htan</td>\n",
              "      <td>i</td>\n",
              "      <td>would</td>\n",
              "      <td>like</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>and</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>xxbos</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>chapter</td>\n",
              "      <td>,</td>\n",
              "      <td>we</td>\n",
              "      <td>will</td>\n",
              "      <td>go</td>\n",
              "      <td>over</td>\n",
              "      <td>what</td>\n",
              "      <td>has</td>\n",
              "      <td>been</td>\n",
              "      <td>done</td>\n",
              "      <td>previously</td>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>and</td>\n",
              "      <td>try</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>best</td>\n",
              "      <td>thing</td>\n",
              "      <td>that</td>\n",
              "      <td>ever</td>\n",
              "      <td>got</td>\n",
              "      <td>into</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>history</td>\n",
              "      <td>of</td>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>these</td>\n",
              "      <td>leaves</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>frank</td>\n",
              "      <td>i</td>\n",
              "      <td>never</td>\n",
              "      <td>expected</td>\n",
              "      <td>me</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>kind</td>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>of</td>\n",
              "      <td>guy</td>\n",
              "      <td>who</td>\n",
              "      <td>would</td>\n",
              "      <td>follow</td>\n",
              "      <td>through</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>but</td>\n",
              "      <td>what</td>\n",
              "      <td>do</td>\n",
              "      <td>you</td>\n",
              "      <td>kno</td>\n",
              "      <td>here</td>\n",
              "      <td>we</td>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>are</td>\n",
              "      <td>doing</td>\n",
              "      <td>what</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>worst</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>you</td>\n",
              "      <td>ca</td>\n",
              "      <td>n't</td>\n",
              "      <td>be</td>\n",
              "      <td>at</td>\n",
              "      <td>your</td>\n",
              "      <td>best</td>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>everytime</td>\n",
              "      <td>,</td>\n",
              "      <td>however</td>\n",
              "      <td>the</td>\n",
              "      <td>problem</td>\n",
              "      <td>is</td>\n",
              "      <td>i</td>\n",
              "      <td>am</td>\n",
              "      <td>at</td>\n",
              "      <td>my</td>\n",
              "      <td>worst</td>\n",
              "      <td>more</td>\n",
              "      <td>time</td>\n",
              "      <td>htan</td>\n",
              "      <td>i</td>\n",
              "      <td>would</td>\n",
              "      <td>like</td>\n",
              "      <td>.</td>\n",
              "      <td>xxmaj</td>\n",
              "      <td>and</td>\n",
              "      <td>to</td>\n",
              "      <td>make</td>\n",
              "      <td>matters</td>\n",
              "      <td>worse</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>[xxbos, xxmaj, in, this, chapter, ,, we, will, go, over, what, has, been, done, previously, and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[and, try, to, be, the, best, thing, that, ever, got, into, the, the, history, of, these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[these, leaves, ., xxmaj, to, be, frank, i, never, expected, me, to, be, the, kind, of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[of, guy, who, would, follow, through, ., xxmaj, but, what, do, you, kno, here, we, are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[are, doing, what, we, do, worst, ., xxmaj, you, ca, n't, be, at, your, best, everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>[everytime, ,, however, the, problem, is, i, am, at, my, worst, more, time, htan, i, would, like, ., xxmaj, and, to, make, matters, worse, i, rarely, learn, .]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAg9B7QKM66J"
      },
      "source": [
        "we need to transform texts inot a stream by concatenating them together. As with images it is best to randomize order of documents (not the text!)\n",
        "\n",
        "Then we cut the stream to batch which is our batch size. for instance if stream is 50000 then we set a batch size of 10 this will give us 10 mini streams of 5000 tokens\n",
        "\n",
        "this is the behindthe scenes for fastai librart when we create LMDataLoader. we do it when we apply Numericalize\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfVynKMWMXEv"
      },
      "source": [
        "nums200 = toks200.map(num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C44JSyAOaJd"
      },
      "source": [
        "dl = LMDataLoader(nums200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wz4T3c6MOgg_",
        "outputId": "f240b626-b71e-4090-f748-b947ebd71a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# grabbing the first batch\n",
        "x,y = first(dl)\n",
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 72]), torch.Size([64, 72]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "keMUY-kFO_EX",
        "outputId": "e546a666-8660-494a-ffe5-29b623529a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "x[0][:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  2,   8,  67,  41,  13, 440,  14, 207,  19,  41,  42,   0,  10, 281,  20,  16,  42, 130, 515, 247])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnCbJW8KOwe3",
        "outputId": "48c96dec-510f-493b-a7c0-ad5e75fb9098",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "' '.join([num.vocab[o] for o in x[0][:20]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'xxbos xxmaj there are a number of things that are not xxunk , although this is not too important since'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIQySG4nPNxd"
      },
      "source": [
        "### Training a Text classifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J05RvDOqPMrW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}